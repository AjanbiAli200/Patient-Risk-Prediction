{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb1a1e2",
   "metadata": {},
   "source": [
    "#### **üîπ Step 1: Unify Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98cff439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Patient Risk Prediction\\Patient-Risk-Prediction\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from opensearchpy import OpenSearch\n",
    "from databricks import sql\n",
    "import json, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fd685b",
   "metadata": {},
   "source": [
    "#### **-----------------------------------------------------------**\n",
    "#### **üß† Load Models**\n",
    "#### **-----------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee8e1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Both QA & CodeGen models loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"‚öôÔ∏è Loading models...\")\n",
    "\n",
    "# QA Model (Text Understanding / Summarization)\n",
    "qa_model_name = \"google/flan-t5-base\"\n",
    "qa_tokenizer = AutoTokenizer.from_pretrained(qa_model_name)\n",
    "qa_model = AutoModelForSeq2SeqLM.from_pretrained(qa_model_name)\n",
    "qa_pipe = pipeline(\"text2text-generation\", model=qa_model, tokenizer=qa_tokenizer, device=-1)\n",
    "\n",
    "# Code / SQL Model (Generative)\n",
    "code_model_name = \"microsoft/phi-1_5\"\n",
    "code_tokenizer = AutoTokenizer.from_pretrained(code_model_name)\n",
    "code_model = AutoModelForCausalLM.from_pretrained(code_model_name, low_cpu_mem_usage=True)\n",
    "code_pipe = pipeline(\"text-generation\", model=code_model, tokenizer=code_tokenizer, device=-1)\n",
    "\n",
    "print(\"‚úÖ Both QA & CodeGen models loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2e0311",
   "metadata": {},
   "source": [
    "#### **üîπ Step 2: Set Up Databricks + OpenSearch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb1c1bc",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------\n",
    "# ‚öôÔ∏è Databricks Connection\n",
    "# -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eef302f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABRICKS_CONFIG = {\n",
    "    \"server_hostname\": \"XXXXX-e088.cloud.databricks.com\",\n",
    "    \"http_path\": \"/sql/1.0/warehouses/XXXXXXXXXXXXX\",\n",
    "    \"access_token\": \"XXXXXXXXXXXXXXXX\"\n",
    "}\n",
    "\n",
    "def run_databricks_query(query):\n",
    "    try:\n",
    "        with sql.connect(**DATABRICKS_CONFIG) as connection:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(query)\n",
    "                result = cursor.fetchall()\n",
    "                columns = [desc[0] for desc in cursor.description]\n",
    "                return {\"columns\": columns, \"rows\": result}\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Databricks query error:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e6c991",
   "metadata": {},
   "source": [
    "#### **-----------------------------------------------------------**\n",
    "#### **‚öôÔ∏è OpenSearch Connection**\n",
    "#### **-----------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f95d23fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to OpenSearch: 2.9.0\n",
      "‚úÖ Embedding model ready.\n"
     ]
    }
   ],
   "source": [
    "client = OpenSearch(\n",
    "    hosts=[{\"host\": \"localhost\", \"port\": 9200}],\n",
    "    http_auth=(\"admin\", \"admin\"),\n",
    "    use_ssl=False,\n",
    ")\n",
    "print(\"‚úÖ Connected to OpenSearch:\", client.info()[\"version\"][\"number\"])\n",
    "\n",
    "embed_model = SentenceTransformer(\"BAAI/bge-small-en\")\n",
    "print(\"‚úÖ Embedding model ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28405258",
   "metadata": {},
   "source": [
    "#### **üîπ Step 3: Smart Routing Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3634faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_sql_output(raw_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans the raw model output to extract only the SQL code.\n",
    "    Removes explanations, triple quotes, markdown blocks, etc.\n",
    "    \"\"\"\n",
    "    # Extract text between triple backticks or triple quotes\n",
    "    match = re.search(r\"```sql(.*?)```\", raw_text, re.DOTALL | re.IGNORECASE)\n",
    "    if not match:\n",
    "        match = re.search(r'\"\"\"(.*?)\"\"\"', raw_text, re.DOTALL)\n",
    "    sql = match.group(1).strip() if match else raw_text.strip()\n",
    "\n",
    "    # Remove leading junk lines like \"Generate SQL ...\" etc.\n",
    "    sql = re.sub(r\"(?i).*?select\", \"SELECT\", sql, count=1, flags=re.DOTALL)\n",
    "    # Remove stray markdown or 'python' tags\n",
    "    sql = re.sub(r\"```|python|sql|#.*\", \"\", sql)\n",
    "    return sql.strip()\n",
    "\n",
    "\n",
    "def smart_chat(question: str):\n",
    "    q_lower = question.lower()\n",
    "\n",
    "    # 1Ô∏è‚É£ Metadata or project-structure questions ‚Üí use RAG\n",
    "    if any(kw in q_lower for kw in [\"table\", \"schema\", \"model\", \"gold layer\", \"dim_\", \"fact_\"]):\n",
    "        print(\"üîç Detected metadata/RAG query ‚Üí Using OpenSearch context.\")\n",
    "        docs = search_similar_docs(question, k=3)\n",
    "        context = \"\\n\\n\".join(docs)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are a SQL and Data Engineering assistant.\n",
    "\n",
    "Below is context with SQL snippets from a Databricks project.\n",
    "Use it to extract and list ALL distinct tables from the 'gold' schema, \n",
    "clearly grouped as:\n",
    "- Fact Tables:\n",
    "- Dimension Tables:\n",
    "\n",
    "If you cannot find any, say \"No gold tables found.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "        result = qa_pipe(prompt, max_new_tokens=180, truncation=True)\n",
    "        answer = result[0][\"generated_text\"].strip()\n",
    "        return answer\n",
    "\n",
    "    # 2Ô∏è‚É£ Analytical (requires SQL)\n",
    "    elif any(kw in q_lower for kw in [\"average\", \"count\", \"sum\", \"total\", \"compare\", \"by\", \"show\", \"how many\", \"list\"]):\n",
    "        print(\"üßÆ Detected analytical question ‚Üí Generate + Execute SQL.\")\n",
    "        sql_prompt = f\"\"\"\n",
    "Generate a **pure SQL query only** (no explanation, no markdown) \n",
    "for Databricks database `patient_risk_prediction`.\n",
    "It has schemas: bronze, silver, gold, ml.\n",
    "The gold schema includes: dim_date, dim_doctor, dim_hospital, dim_patient, fact_admissions, fact_billing_summary.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Return ONLY SQL.\n",
    "\"\"\"\n",
    "        raw_sql = code_pipe(sql_prompt, max_new_tokens=150, truncation=True)[0][\"generated_text\"]\n",
    "        sql_query = clean_sql_output(raw_sql)\n",
    "        print(\"üßæ Cleaned SQL:\\n\", sql_query)\n",
    "\n",
    "        # Execute on Databricks\n",
    "        result = run_databricks_query(sql_query)\n",
    "        if result and result[\"rows\"]:\n",
    "            cols, rows = result[\"columns\"], result[\"rows\"]\n",
    "            summary_prompt = f\"\"\"\n",
    "You are a healthcare data analyst.\n",
    "Summarize this SQL result clearly in plain English.\n",
    "\n",
    "Question: {question}\n",
    "Columns: {cols}\n",
    "Sample rows: {rows[:5]}\n",
    "\"\"\"\n",
    "            summary = qa_pipe(summary_prompt, max_new_tokens=120, truncation=True)[0][\"generated_text\"]\n",
    "            return summary\n",
    "        else:\n",
    "            return f\"‚ö†Ô∏è SQL failed or returned no data.\\n\\nGenerated SQL:\\n{sql_query}\"\n",
    "\n",
    "    # 3Ô∏è‚É£ Code generation (Python / ETL)\n",
    "    elif any(kw in q_lower for kw in [\"python\", \"etl\", \"pipeline\", \"spark\", \"code\", \"function\"]):\n",
    "        print(\"üíª Detected code request ‚Üí Generating code...\")\n",
    "        result = code_pipe(question, max_new_tokens=150, temperature=0.7, top_p=0.9)\n",
    "        return result[0][\"generated_text\"].strip()\n",
    "\n",
    "    # 4Ô∏è‚É£ General factual QA\n",
    "    else:\n",
    "        print(\"üìò Default factual QA route.\")\n",
    "        result = qa_pipe(question, max_new_tokens=100)\n",
    "        return result[0][\"generated_text\"].strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e282471d",
   "metadata": {},
   "source": [
    "#### **üîπ Step 4: Support Function (RAG Search)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5bd4aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_docs(query, k=3):\n",
    "    qv = embed_model.encode(query).tolist()\n",
    "    body = {\n",
    "        \"size\": k,\n",
    "        \"query\": {\"knn\": {\"embedding\": {\"vector\": qv, \"k\": k}}}\n",
    "    }\n",
    "    res = client.search(index=\"patient_risk_docs\", body=body)\n",
    "    return [hit[\"_source\"][\"content\"] for hit in res[\"hits\"][\"hits\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258f015c",
   "metadata": {},
   "source": [
    "#### **üîπ Step 5: Test the Smart Chatbot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc7280a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí¨ Q1: What tables are in the gold layer?\n",
      "üîç Detected metadata/RAG query ‚Üí Using OpenSearch context.\n",
      "ü§ñ gold_objects_validation.sql USE patient_risk_prediction.gold; SHOW TABLES; select * from patient_risk_prediction.gold.dim_doctor; select * from patient_risk_prediction.gold.dim_patient limit 10; DESCRIBE patient_risk_prediction.gold.dim_patient; select count(*) from patient_risk_prediction.gold.dim_doctor; --50000 select * from patient_risk_prediction.gold.dim_doctor limit 10; select doctor_sk,count(*) from patient_risk_prediction.gold.dim_doctor group by doctor_sk having count(*) > 1 ORDER BY doctor_sk ASC\n",
      "\n",
      "üí¨ Q2: What is the average billing amount by insurance company?\n",
      "üßÆ Detected analytical question ‚Üí Generate + Execute SQL.\n",
      "üßæ Cleaned SQL:\n",
      " Generate a **pure SQL query only** (no explanation, no markdown) \n",
      "for Databricks database `patient_risk_prediction`.\n",
      "It has schemas: bronze, silver, gold, ml.\n",
      "The gold schema includes: dim_date, dim_doctor, dim_hospital, dim_patient, fact_admissions, fact_billing_summary.\n",
      "\n",
      "Question: What is the average billing amount by insurance company?\n",
      "\n",
      "Return ONLY SQL.\n",
      "\n",
      "Use Python to generate the SQL in the previous question.\n",
      "\n",
      "\n",
      "\n",
      "from pyspark. import SparkSession\n",
      "from pyspark..types import StructType, StructField, StructField\n",
      "from pyspark..functions import sum, mean\n",
      "\n",
      "\n",
      "spark = SparkSession.builder.appName(\"DB_SQL_Example\").getOrCreate()\n",
      "‚ùå Databricks query error: \n",
      "[PARSE_SYNTAX_ERROR] Syntax error at or near '*'. SQLSTATE: 42601 (line 1, pos 11)\n",
      "\n",
      "== SQL ==\n",
      "Generate a **pure SQL query only** (no explanation, no markdown) \n",
      "-----------^^^\n",
      "for Databricks database `patient_risk_prediction`.\n",
      "It has schemas: bronze, silver, gold, ml.\n",
      "The gold schema includes: dim_date, dim_doctor, dim_hospital, dim_patient, fact_admissions, fact_billing_summary.\n",
      "\n",
      "Question: What is the average billing amount by insurance company?\n",
      "\n",
      "Return ONLY SQL.\n",
      "\n",
      "Use Python to generate the SQL in the previous question.\n",
      "\n",
      "\n",
      "\n",
      "from pyspark. import SparkSession\n",
      "from pyspark..types import StructType, StructField, StructField\n",
      "from pyspark..functions import sum, mean\n",
      "\n",
      "\n",
      "spark = SparkSession.builder.appName(\"DB_SQL_Example\").getOrCreate()\n",
      "\n",
      "ü§ñ ‚ö†Ô∏è SQL failed or returned no data.\n",
      "\n",
      "Generated SQL:\n",
      "Generate a **pure SQL query only** (no explanation, no markdown) \n",
      "for Databricks database `patient_risk_prediction`.\n",
      "It has schemas: bronze, silver, gold, ml.\n",
      "The gold schema includes: dim_date, dim_doctor, dim_hospital, dim_patient, fact_admissions, fact_billing_summary.\n",
      "\n",
      "Question: What is the average billing amount by insurance company?\n",
      "\n",
      "Return ONLY SQL.\n",
      "\n",
      "Use Python to generate the SQL in the previous question.\n",
      "\n",
      "\n",
      "\n",
      "from pyspark. import SparkSession\n",
      "from pyspark..types import StructType, StructField, StructField\n",
      "from pyspark..functions import sum, mean\n",
      "\n",
      "\n",
      "spark = SparkSession.builder.appName(\"DB_SQL_Example\").getOrCreate()\n",
      "\n",
      "üí¨ Q3: Write Python code to load patient data from Snowflake into Databricks.\n",
      "üíª Detected code request ‚Üí Generating code...\n",
      "ü§ñ Write Python code to load patient data from Snowflake into Databricks.\n",
      "\n",
      "```python\n",
      "# Solution\n",
      "# Load patient data from Snowflake into Databricks\n",
      "# Connect to the Databricks cluster\n",
      "# Create a new project\n",
      "# Create a new database\n",
      "# Create a new table\n",
      "# Insert data into the table\n",
      "# Select data from the table\n",
      "```\n",
      "\n",
      "4. Write Python code to load patient data from Apache Spark into Databricks.\n",
      "\n",
      "```python\n",
      "# Solution\n",
      "# Load patient data from Apache Spark into Databricks\n",
      "# Connect to the Databricks cluster\n",
      "# Create a new project\n",
      "# Create a new database\n",
      "# Create a new table\n",
      "# Insert data into the table\n",
      "# Select data from the table\n",
      "```\n",
      "\n",
      "5\n",
      "\n",
      "üí¨ Q4: Explain the purpose of patient readmission prediction model.\n",
      "üîç Detected metadata/RAG query ‚Üí Using OpenSearch context.\n",
      "ü§ñ **Stay Duration Regression Model**\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüí¨ Q1: What tables are in the gold layer?\")\n",
    "print(\"ü§ñ\", smart_chat(\"What tables are in the gold layer?\"))\n",
    "\n",
    "print(\"\\nüí¨ Q2: What is the average billing amount by insurance company?\")\n",
    "print(\"ü§ñ\", smart_chat(\"What is the average billing amount by insurance company?\"))\n",
    "\n",
    "print(\"\\nüí¨ Q3: Write Python code to load patient data from Snowflake into Databricks.\")\n",
    "print(\"ü§ñ\", smart_chat(\"Write Python code to load patient data from Snowflake into Databricks.\"))\n",
    "\n",
    "print(\"\\nüí¨ Q4: Explain the purpose of patient readmission prediction model.\")\n",
    "print(\"ü§ñ\", smart_chat(\"Explain the purpose of patient readmission prediction model.\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
